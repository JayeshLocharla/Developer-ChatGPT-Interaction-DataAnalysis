{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGLJRtZyIjco"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Opening JSON file\n",
        "with open('/content/drive/MyDrive/20230727_195816_hn_sharings.json', 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# List to store prompts and answers\n",
        "all_conversations = []\n",
        "\n",
        "# Iterate through the structure and extract prompts and answers\n",
        "for source in data.get('Sources', []):\n",
        "    for chat in source.get('ChatgptSharing', []):\n",
        "        if \"NumberOfPrompts\" in chat and chat[\"NumberOfPrompts\"] == 1:\n",
        "            prompt = chat[\"Conversations\"][0].get(\"Prompt\", \"\")\n",
        "            answer = chat[\"Conversations\"][0].get(\"Answer\", \"\")\n",
        "            all_conversations.append({\"Answer\": answer})\n",
        "\n",
        "# # Write all prompts and answers to a new JSON file\n",
        "file_path = \"/content/drive/MyDrive/ans.txt\"\n",
        "with open(file_path, 'a') as json_file:\n",
        "    json.dump(all_conversations, json_file, indent=4)\n",
        "\n",
        "# print(\"All prompts and answers saved to samp4.json\")\n",
        "# Prompts gathered from \"/content/DevGPT/snapshot_20230727\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        dataset = file.readlines()\n",
        "    return dataset\n",
        "\n",
        "def search_dataset(keywords, dataset):\n",
        "    # Initialize counters for each keyword\n",
        "    keyword_counts = {keyword: 0 for keyword in keywords}\n",
        "    without_keywords_count = 0\n",
        "\n",
        "    # Iterate through the dataset\n",
        "    for entry in dataset:\n",
        "        # Check if any of the keywords are present in the entry\n",
        "        found_keyword = False\n",
        "        for keyword in keywords:\n",
        "            if keyword.lower() in entry.lower():\n",
        "                keyword_counts[keyword] += 1\n",
        "                found_keyword = True\n",
        "                break  # Break the loop once a keyword is found in the entry\n",
        "\n",
        "        # If none of the keywords are found, increment the without_keywords_count\n",
        "        if not found_keyword:\n",
        "            without_keywords_count += 1\n",
        "\n",
        "    # Print the results\n",
        "    for keyword, count in keyword_counts.items():\n",
        "        print(f\"Number of entries with the keyword '{keyword}': {count}\")\n",
        "\n",
        "    print(f\"Number of entries without any of the keywords: {without_keywords_count}\")\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/drive/MyDrive/ans.json'\n",
        "dataset = load_dataset_from_file(file_path)\n",
        "keywords_to_search = [\"sorry\", \"can't\", \"last update\",\"apologize\"]\n",
        "search_dataset(keywords_to_search, dataset)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7ow5Rz-MfRO",
        "outputId": "f998e00d-7b3a-473d-f29c-d468f89eb1c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries with the keyword 'sorry': 4\n",
            "Number of entries with the keyword 'can't': 8\n",
            "Number of entries with the keyword 'last update': 2\n",
            "Number of entries with the keyword 'apologize': 4\n",
            "Number of entries without any of the keywords: 573\n"
          ]
        }
      ]
    }
  ]
}